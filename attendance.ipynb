{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FACE RECOGNITION ATTENDANCE MANAGEMENT SYSTEM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use can use cv2 by installing pip install opencv-python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use CascadeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\swapn\\AppData\\Local\\Temp\\ipykernel_33332\\1210666039.py:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCollecting samples is completed!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[39m# Calling the created function \u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m generate_dataset()\n",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_dataset\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     face_classifier \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCascadeClassifier(\u001b[39m\"\u001b[39m\u001b[39mhaarcascade_frontalface_alt2.xml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[39m# To separate face from image\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mface_cropped\u001b[39m(img):\n\u001b[0;32m      6\u001b[0m         \u001b[39m# Converting image to greyscale\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_dataset():\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_alt2.xml\")\n",
    "    \n",
    "    # To separate face from image\n",
    "    def face_cropped(img):\n",
    "        # Converting image to greyscale\n",
    "        gray =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # 1.1 is the scaling factor\n",
    "        # 4 minimum diverse\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        # () denotes empty\n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+w), (0,0,255), 2)\n",
    "            cropped_face = img[y:y+h,x:x+w]\n",
    "\n",
    "        return cropped_face\n",
    "    \n",
    "    # Opening web cam\n",
    "    # 0 for internal camera\n",
    "    # 1 for external camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    img_id = 0\n",
    "\n",
    "    while True:\n",
    "        # this is our image frame\n",
    "        ret, frame = cap.read()\n",
    "        # if face is found\n",
    "        if face_cropped(frame) is not None:\n",
    "            img_id+=1\n",
    "            face = cv2.resize(face_cropped(frame), (200, 200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            # save image in this data folder\n",
    "            file_name_path = \"data/\" + \"Swapnita_\" + str(img_id) + \".jpg\"\n",
    "            # to save image face in file_name_path\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "\n",
    "            # putText method to count\n",
    "            # to put image id on the face\n",
    "            # (50,50) is the origin point\n",
    "            # font in which text is to be written\n",
    "            # font scale 1\n",
    "            # 0,255,0 is green in RGB\n",
    "            # 2 is thickness\n",
    "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Cropped Face is title and face is displayed\n",
    "            cv2.imshow(\"Cropped_Face\", face)\n",
    "            # if we press enter or image id is 1000 we break the loop\n",
    "            # 13 is the ASCII value of enter\n",
    "            if cv2.waitKey(1)==13 or int(img_id)==50:\n",
    "                break\n",
    "\n",
    "    # releasing the camera and distroying all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Collecting samples is completed!\")\n",
    "\n",
    "# Calling the created function \n",
    "generate_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can install numpy by using pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_name is the parameter of the created function\n",
    "def my_label(image_name):\n",
    "    name = image_name.split('.')[-3]\n",
    "    # if you have 2 people in your dataset\n",
    "    if name == \"Swapnita\":\n",
    "        return np.array([1,0])\n",
    "    elif name == \"Shreya\":\n",
    "        return np.array([0,1])\n",
    "    \n",
    "    # If you have 3 people in the dataset\n",
    "    #if name == \"Swapnita\":\n",
    "    #    return np.array([1,0,0])\n",
    "    #elif name == \"Shruti\":\n",
    "    #    return np.array([0,1,0])\n",
    "    #elif name == \"Khushi\":\n",
    "    #    return np.array([0,0,1])   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data\n",
    "Now, we need to create dataset from the collected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_data():\n",
    "    # Creating an empty list tqdm\n",
    "    data = []\n",
    "    for img in tqdm(os.listdir(\"data\")):\n",
    "        path = os.path.join(\"data\",img)\n",
    "        img_data = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50,50))\n",
    "        data.append([np.array(img_data)])\n",
    "    shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = my_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:2400]\n",
    "test = data[2400:]\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1, 50, 50, 1)\n",
    "print(X_train.shape)\n",
    "Y_train = [i[1] for i in train]\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1, 50, 50, 1)\n",
    "print(X_test.shape)\n",
    "Y_test = [i[1] for i in test]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "fromtflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "convnet = input_data(shape=[50,50,1])\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "#32 filters and stride=5 so that the filter will move 5 pixel or unit at a time\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 3, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossenthropy')\n",
    "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
    "model.fit(X.train, Y_train, n_epoch=12, validation_set=(X_test, Y_test), show_metric = True, run_id=\"FRS\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the data and making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_visualization():\n",
    "    Vdata = []\n",
    "    for img in tqdm(os.listdir(\"Images for visualization\")):\n",
    "        path = os.path.join(\"Images for visualization\", img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50, 50))\n",
    "        Vdata.append([np.array(img_data), img_num])\n",
    "    shuffle(Vdata)\n",
    "    return Vdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vdata = data_for_visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "for num, data in enumerate(Vdata[:20]):\n",
    "    img_data = data[0]\n",
    "    y = fig.add_subplot(5,5, num+1)\n",
    "    image = img_data\n",
    "    data = img_data.reshape(50, 50, 1)\n",
    "    model_out = model.predict([data])[0]\n",
    "\n",
    "    if np.argmax(model_out) == 0:\n",
    "        my_label = 'Swapnita'\n",
    "    elif np.argmax(model_out) == 1:\n",
    "        my_label = 'Shruti'\n",
    "    else:\n",
    "        my_label = 'Khushi'\n",
    "\n",
    "    y.imshow(image, cmap='gray')\n",
    "    plt.title(my_label)\n",
    "\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
